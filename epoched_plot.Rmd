---
title: "R Notebook for GAM"
output: html_notebook
---

This is a notebook version of epoched plot.R  

GAM model (without contrasts) for LISA data (Word Generation) - simple stimulus (stim1 and stim2) - both runs  

!!!!!!!!!!!! DB comment:
Script says not downsampled, but this IS downsampled early on by taking every 4th point:  at this line: rawdata = filter(shortdat, row_number() %% 4 == 0)

```{r loadpackages}
library(osfr)
library(utils)
require(dplyr)
require(tidyverse)
require(boot)
require(fmri)
require(ggpubr)
library(psych)
#library(nlme)
library(plm)
require(mgcv)
library(blandr)
library(gratia)
library(performance)
library(GGally)
library(here)
```

The following is the main function to run the analysis. The function does the following in order:

PART 1:  

   Script takes a raw .exp datafile and preprocesses it ready for GAM analysis:  
   - It creates a box car function showing when the task was ON or OFF  
   - It normalises the fTCD signal to a mean of 100  
   - It performs heart beat integration  
   - It saves the processed data into a .csv file  
  
 PART 2:  

   - runs the gam  
   - saves the parameter estimates to data.frame.  

 PART 3:  

   - plot the correlogram, Bland Altman plots, time series plots.  

```{r set-parameters}


  origWG <- read.csv(here('Bruckert_2016_data/WordGen_results.csv')) #this has laterality classification from original doppler  
  #For now, just analyse 1 file - we'll start with left-lateralised
  w<-which(origWG$lat=='R')
  thisfile <- 3 #after grouping by lat, this is the nth file
j <- w[thisfile] #number of file to be analysed specified here


  ## Set parameters and make file to hold results
  samplingrate <- 25 # Sampling rate after downsampling. Raw data is 100Hz, we take 1 in every 4 samples
  heartratemax <- 125
  
  # set up data.frame to hold the outputted parameter estimates from the GLMs.
  order=3 #used later for the polynomial order
  
        # Stimulus timings: Word Gen starts 5 seconds after marker and continues for 20 seconds (including REPORT phase)
    # Edit: stim1 models covert word generation, which starts 5 seconds after marker and continues for 15 seconds
    # stim2 models overt word reporting, which starts 20 seconds after marker and continues for 5 seconds
    stim1_delay_sec <- 5
    stim1_delay_samples <- stim1_delay_sec * samplingrate
    stim1_length_sec <- 15
    stim1_length_samples <- stim1_length_sec * samplingrate
    
    stim2_delay_sec <- 20
    stim2_delay_samples <- stim2_delay_sec * samplingrate
    stim2_length_sec <- 5
    stim2_length_samples <- stim2_length_sec * samplingrate
    
    rest_length_sec <- 30
    rest_length_samples <- rest_length_sec * samplingrate
    
mypath<-here("/Users/dorothybishop/Rprojects/GAM_laterality/Bruckert_2016_data/Chpt4_fTCD_WordGen_rawdata")
 allfiles<-list.files(mypath,pattern = '.exp')
  
  glm.data<-data.frame(matrix(NA,nrow=length(allfiles),ncol=11))
  names(glm.data)<-c('ID',paste0('param',1:5),'HRF','AIC_glm','AIC_gam','BIC_glm','BIC_gam')
  glm.data$ID<-allfiles




```
  
```{r do-gamma-function}  
fTCD_gamma_LISA_GAM<-function(path,Nfile) #DB added option Nfile so this just runs one person at a time so I can understand it better!  #NFile is the order of one file in the filelist
{
  # get all files names to be loaded in and preprocessed
  filename1<-list.files(path,pattern = '.exp')[Nfile]
  
  #------------------------------------------------------------------------------------------------#
  ###########################################
  # PART 1: based on original fTCD analysis #
  #                                         #
  # Created by z.woodhead 30th July 2019    #
  # Edited  by z. woodhead 3rd Oct 2019     #
  ###########################################
  #------------------------------------------------------------------------------------------------#
#fit single GAM for each individual.
 
    print(filename1)
    
    ## Read in raw data
    
 
    mydata<-read.table(paste0(path,"/",filename1), skip = 6,  header =FALSE, sep ='\t')
    
    wantcols = c(2,3,4,7) #sec, L, R,marker #select columns of interest to put in shortdat
    #NB markers correspond to values > 100 - should be around 24 short blocks of these- can see these with plot(shortdat$V7) for sanity check here
    shortdat = data.frame(mydata[,wantcols])
    rawdata = filter(shortdat, row_number() %% 4 == 0) # downsample to 5 Hz by taking every 20th point (nb we still see markers, as duration of marker signal is much longer than 4 timepoints)
    allpts = nrow(rawdata) # total N points in long file
    rawdata[,1] = (seq(from=1,to=allpts*4,by=4)-1)/100 #create 1st column which is time in seconds from start
    colnames(rawdata) = c("sec","L","R","marker")
    
    
    #----------------------------------------------------------
    ## Find markers; place where 'marker' column goes from low to high value
    
    mylen = nrow(rawdata); # Number of timepoints in filtered data (rawdata)
    markerplus = c(rawdata$marker[1] ,rawdata$marker); # create vectors with offset of one
    markerchan = c(rawdata$marker,0); 
    markersub = markerchan - markerplus; # start of marker indicated by large difference between consecutive data points
    meanmarker <- mean(rawdata$marker) # We will identify big changes in marker value that are > 5 sds
    markersize <- meanmarker+4*sd(rawdata$marker)
    origmarkerlist = which(markersub>markersize)
    norigmarkers = length(origmarkerlist)
    

    
    rawdata$stim1_on <- 0
    rawdata$stim2_on <- 0
    for (m in 1:norigmarkers){
      rawdata$stim1_on[(origmarkerlist[m]+stim1_delay_samples):(origmarkerlist[m]+stim1_delay_samples+stim1_length_samples)] <- 1
      rawdata$stim2_on[(origmarkerlist[m]+stim2_delay_samples):(origmarkerlist[m]+stim2_delay_samples+stim2_length_samples)] <- 1
    }
    #---------------------------------------------------------- (ZW NEW)
    # Identify raw datapoints below .0001 quartile (dropout_points) and above .9999 quartile (spike_points)
    
    dropout_points <- c(which(rawdata$L < quantile(rawdata$L, .0001)), 
                        which(rawdata$R < quantile(rawdata$R, .0001)))
    
    spike_points <- c(which(rawdata$L > quantile(rawdata$L, .9999)),
                      which(rawdata$R > quantile(rawdata$R, .9999)))
    
    #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
    #DB_June : these points are identified but not smoothed/deleted prior to normalisation?
    #I suggest omitted from computation of mean (though it doesn't make much difference)
  
    
    #----------------------------------------------------------
    # Data normalisation
    
    meanL=mean(rawdata$L[-c(dropout_points,spike_points)])
     meanR=mean(rawdata$R[-c(dropout_points,spike_points)])
    rawdata$normal_L=rawdata$L/meanL * 100 
    rawdata$normal_R=rawdata$R/meanR * 100
    #For the dropout and spiking timepoints, substitute the mean
     rawdata$normal_L[c(dropout_points,spike_points)]<-meanL
    rawdata$normal_R[c(dropout_points,spike_points)]<-meanR
    #----------------------------------------------------------
    # Heartbeat integration
    peaklist=numeric(0)
    pdiff=numeric(0)
    badp=numeric(0)
    
    # Look through every sample from 6, to number of samples minus 6
    for(i in seq(6,mylen-6))
    {if(
      (rawdata$L[i] > rawdata$L[i-5])
      & (rawdata$L[i] > rawdata$L[i-4])
      & (rawdata$L[i] > rawdata$L[i-3])
      & (rawdata$L[i] > rawdata$L[i-2])
      & (rawdata$L[i] > rawdata$L[i-1])
      & (rawdata$L[i] > rawdata$L[i+1])
      & (rawdata$L[i] > rawdata$L[i+2])
      & (rawdata$L[i] > rawdata$L[i+3])
      & (rawdata$L[i]> rawdata$L[i+4])
      & (rawdata$L[i]> rawdata$L[i+5]))
    {peaklist=c(peaklist,i)
    }
    }
    
    # Check that the heartbeats are spaced by far enough!
    peakdiffmin = 60/heartratemax * samplingrate
    pdiff <- peaklist[2:length(peaklist)]-peaklist[1:(length(peaklist)-1)] # pdiff is a list of the number of samples between peaks
    badp<-which(pdiff<peakdiffmin) # badp is a list of the pdiff values that are less than peakdiffmin
    if (length(badp) != 0)
    {peaklist<-peaklist[-(badp+1)] # update peaklist, removing peaks identified by badp
    }
    #print(dim(rawdata))
    #print(peaklist)
    # Do heart beat integration
    peakn=length(peaklist)
    rawdata$heartbeatcorrected_L <- 0
    rawdata$heartbeatcorrected_R <- 0 
    for (p in 1:(peakn-1))
    {myrange=seq(peaklist[p],peaklist[p+1]) # the indices where the heartbeat will be replaced
    thisheart_L=mean(rawdata$normal_L[myrange]) # the new values that will be replaced
    thisheart_R=mean(rawdata$normal_R[myrange])
    rawdata$heartbeatcorrected_L[peaklist[p] : peaklist[p+1]]=thisheart_L
    rawdata$heartbeatcorrected_R[peaklist[p] : peaklist[p+1]]=thisheart_R
    if (p==1){
      rawdata$heartbeatcorrected_L[1:peaklist[p]] <- thisheart_L
      rawdata$heartbeatcorrected_R[1:peaklist[p]] <- thisheart_R
    }
    if (p==peakn-1){
      rawdata$heartbeatcorrected_L[peaklist[p] : mylen] <- thisheart_L
      rawdata$heartbeatcorrected_R[peaklist[p] : mylen] <- thisheart_R
    }
    }
    
    #To inspect a portion of the data can run this:
    seemarkers<-0 #nb usually set seemarkers to zero.
    if(seemarkers==1){
    plot(rawdata$sec[1:5000],rawdata$heartbeatcorrected_L[1:5000],type='l',col='blue')
    lines(rawdata$sec[1:5000],rawdata$heartbeatcorrected_R[1:5000],type='l',col='red')
    lines(rawdata$sec[1:5000],120*rawdata$stim1_on[1:5000]) #marker superimposed as block
    }
    #--------------------------------------------------------------------------------------------
    # Identify extreme datapoints with values below 60 and above 140
    #!!!!!!!!!!!!!!!!!
    # DB These are not excluded or smoothed prior to normalisation or heartbeat correction?
    
      
    extreme_points <- c(which(rawdata$heartbeatcorrected_L < 60),
                        which(rawdata$heartbeatcorrected_L > 140),
                        which(rawdata$heartbeatcorrected_R < 60),
                        which(rawdata$heartbeatcorrected_R > 140))
    
    #DB new
    rawdata$relativetime<-NA #initialise new column
  
    # Epoch timings
    epochstart_time   <- -12
    epochend_time     <- 30
    epochstart_index  <- epochstart_time * samplingrate
    epochend_index    <- epochend_time * samplingrate
    basestart_time    <- -10 # baseline start
    baseend_time      <- 0 # baseline end
    basestart_index   <- basestart_time * samplingrate
    baseend_index    <- baseend_time * samplingrate
    
    # myepoched will be the full epoched trial
    myepoched <- array(0, dim=c(norigmarkers,epochend_index - epochstart_index + 1, 2)) # Set up an empty matrix
    
    for(mym in 1:norigmarkers) # for trials
    { 
      index1 = origmarkerlist[mym] + epochstart_index # index1 is index of the timepoint at the start of the epoch
      index2 = origmarkerlist[mym] + epochend_index # index2 is the index of the timepoint at the end of the epoch
      rawdata$relativetime[index1:index2]<-seq(from=epochstart_time, to=epochend_time, by=.04)
      # If recording started late, the start of the epoch for trial 1 will be beyond the recorded range. 
      # If this doesn't affect the baseline period (ie, results will be unaffected), then replace with mean
      if (index1 < 0 & origmarkerlist[mym] + basestart_index > 0){
        cat("Recording started late. Padding start with zeros", "\n")
        replacement_mean_left = mean(rawdata[0 : index2, 2]) # Left hemisphere mean
        replacement_mean_right = mean(rawdata[0 : index2, 3]) # Right hemisphere mean
        # The epoched data is the heartbeat corrected data (columns 9 and 10 from rawdata)
  
        
        myepoched[mym, ,1] = c(rep(replacement_mean_left,index1*-1+1),rawdata[0:index2,9])
        myepoched[mym, ,2] = c(rep(replacement_mean_right,index1*-1+1),rawdata[0:index2,10])
      }
      
      if (index1 > 1){
        myepoched[mym,,1]=rawdata[index1:index2,9] #L side
        myepoched[mym,,2]=rawdata[index1:index2,10] #R side
      }
    }
    
    # Baseline correction - (added to rawdata by DB)
    basepoints=(basestart_index-epochstart_index):(baseend_index-epochstart_index) #all baseline points within epoch
    
    rawdata$baselinedL<-NA
    rawdata$baselinedR<-NA
    for (mym in 1:norigmarkers)
    {
      index1 = origmarkerlist[mym] + epochstart_index # index1 is index of the timepoint at the start of the epoch
      index2 = origmarkerlist[mym] + epochend_index # index2 is the index of the timepoint at the end of the epoch

    basemeanL=mean(myepoched[mym,basepoints,1]) #last dim is 3, which is HB corrected
    basemeanR=mean(myepoched[mym,basepoints,2])

    myepoched[mym,,1]=100+myepoched[mym,,1]-basemeanL #last dim 4 is HB and baseline
    myepoched[mym,,2]=100+myepoched[mym,,2]-basemeanR
    
    rawdata$baselinedL[index1:index2]<-myepoched[mym,,1]
    rawdata$baselinedR[index1:index2]<-myepoched[mym,,2]
    }
    
    # Average over trials
    ntime <- dim(myepoched)[2]
    myepoched_average <- data.frame(
      "Lmean" <- rep(1, ntime),
      "Rmean" <- rep(1, ntime),
      "LRdiff" <- rep(1, ntime))
    
    myepoched_average$Lmean <- apply(myepoched[ , , 1], c(2), mean)
    myepoched_average$Rmean <- apply(myepoched[ , , 2], c(2), mean)
    myepoched_average$LRdiff <- myepoched_average$Lmean - myepoched_average$Rmean
    
    # # Plot myepoched_average
    
    
    myepoched_average$time<-seq(from=epochstart_time, to=epochend_time, by=.04)
    filepath<-here('GAM_figs')
    filename<-paste0(filepath,"/",origWG$Filename[j],"_avg.jpg")

    longepoched<-rbind(myepoched_average[4:7],myepoched_average[4:7])
    myrange<-1:nrow(myepoched_average)
    
    longepoched$Rmean[myrange]<-longepoched$Lmean[myrange]
    longepoched$Lmean<-'Right'
    longepoched$Lmean[myrange]<-'Left'
    colnames(longepoched)<-c('Side','CBV','diff','time')
    longepoched$Side<-as.factor(longepoched$Side)
    
    
    
     g1<-ggplot(data=longepoched, aes(x=time, y=CBV, group=Side)) +
     geom_line(aes(color=Side))+
     ggtitle(paste0(origWG$Filename[j],':_',origWG$lat[j]))
    
     ggsave(filename,g1)
    
    
    #remove outlier cases
    rawdata$heartbeatcorrected_L[extreme_points]<-NA
    rawdata$heartbeatcorrected_R[extreme_points]<-NA
  
  return(list(rawdata,peaklist))
  }
```
 
    #########################################
    # PART 2                                #
    #                                       #
    # Created by P.Thompson 17th Oct 2019   #
    # Edited by P.Thompson 18th Oct 2019    #
    # Edited by P.Thompson 30th June 2020   #
    #########################################
 
     # Adapted 'fmri.stimulus' function from the R package 'fmri'. This is a condensed version that only gives option of the gamma HRF and convolves the HRF to the stimuli specified earlier in this script
```{r fmri.stimulus.function}   
    fmri.stimulus.PT2<- function(scans,stim,onsets, durations,TR,scale)
    {
      onsets <- onsets * TR #onsets in seconds
      durations <- durations * TR #durations in seconds
      onsets <- onsets * scale #no effect as scale = 1
      durations <- durations * scale #no effect as scale = 1
      scans <- scans * scale # #original script had *TR  ??
      TR <- TR/scale #no effect as scale = 1
      no <- length(onsets) #N markers
      durations <- rep(durations, no) #list of durations of stimulus in seconds
      
      stimulus<-stim
      
      .gammaHRF <- function(t, par = NULL) {
        th <- 0.242 * par[1]
        1/(th * factorial(3)) * (t/th)^3 * exp(-t/th)
      }
      
      
     # par <- floor((durations[1]/28)*4) ???
      par <- durations[1]
      
      #y <- .gammaHRF(0:(durations[1] * scale)/scale, par) 
      
      y <- .gammaHRF(0:durations[1], par) #DB remove scaling 
      
      stimulus <-  convolve(stimulus, rev(y), type = "open")
      stimulus <- stimulus[unique((scale:scans)%/%(scale^2 * TR)) * scale^2 * TR]/(scale^2 * TR)
      stimulus <- stimulus - mean(stimulus)
      return(stimulus)
    }  
    
```   
    



#--------------------------------------------------------------------------------------------------#
# RUN FUNCTION FOR PARTICIPANT DATA 
#--------------------------------------------------------------------------------------------------#



```{r getrawdata}
 #in fact, the listfiles option is done within the function, so I've just added the option of Nfiles, which means we don't have to analyse all of them if we don't want to

#my_results_LISA_WG_GAM_gamma_Jun2022<-fTCD_gamma_LISA_GAM(path=mypath,order=order,Nfiles=1)
myreturn<-fTCD_gamma_LISA_GAM(path=mypath,Nfile=j)
rawdata<-myreturn[[1]]
peaklist<-myreturn[[2]]
#dev.off()



```


```{r convolve}
    # Create convolved stimulus function with HRF (applying the new fmri.stimulus.PT2 function above)

    
    gamma1 = fmri.stimulus.PT2(
      scans = dim(rawdata)[1], 
      stim=rawdata$stim1_on, 
      onsets = c(1,1+which(diff(rawdata$stim1_on)!=0)), 
      durations = stim1_length_samples, 
      TR = 1/25,  #shouldn't this be 1/25?
      scale=1)

    gamma2 = fmri.stimulus.PT2(
      scans = dim(rawdata)[1], 
      stim=rawdata$stim2_on, 
      onsets = c(1,1+which(diff(rawdata$stim2_on)!=0)), #in points
      durations = stim2_length_samples,  #in points
      TR = 1/25, #if set to 1/25, gamma2 does not compute!
      scale=1)
    
if (length(gamma1)<nrow(rawdata)){ #argh length differs - bolt zero on for now
  gamma1<-c(0,gamma1)
  gamma2<-c(0,gamma2)
}
    #temp!
scans = dim(rawdata)[1]
stim=rawdata$stim2_on
onsets = c(1,1+which(diff(rawdata$stim2_on)!=0))
durations = stim2_length_samples
TR = 1/25
scale=1

    #optional plot of gamma functions added by DB
    plot(rawdata$sec[1:length(gamma1)],gamma1,type='l',col='blue')
   lines(rawdata$sec[1:length(gamma2)],gamma2,type='l',col='red')

    
    #-----------------------------------------------------------------------------------------------# 
    # Binds all the stimuli into one matrix to be read into the fmri.design function. This converts the data into a design matrix and adds in the drift terms according to the order argument specified by the user.
    gamma = as.matrix(cbind(gamma1,gamma2))
    gamma = rbind(gamma,gamma) 
    #DB - so just duplicating gamma in 2nd set of rows?
    
    #-----------------------------------------------------------------------------------------------#
    
    # We create the design matrix and bind them together to give the same design matrix for each side (left and right), so that the main effect of side can be modelled appropriately.

    my_des<-fmri.design(gamma, order = order)
    
    # Add a dummy variable for side (signal). This is either 0 or 1 for left and right respectively.
    my_des<-cbind(my_des,rep(1:0,each=length(gamma1)))
    
    #Has this been duplicated in error?
    # Add a dummy variable for side (signal). This is either 0 or 1 for left and right respectively.
     my_des<-cbind(my_des,rep(1:0,each=length(gamma1))) #This line commented out by db
    
    # Add interaction variable for side (signal*stim1).
    my_des[,8]<-my_des[,8]*my_des[,1]
    
    # Use the design matrix to finish constructing the data for each GLM. 
    
    my_des[,7]<-dplyr::recode(my_des[,7], `0` = -1L, `1` = 1L)
    #-----------------------------------------------------------------------------------------------#
    
 
    #DB bit with baselined data
 mybdata<-data.frame(y=c(rawdata$baselinedL,rawdata$baselinedR),stim1=c(gamma1,gamma1),stim2=c(gamma2,gamma2),t=c(rawdata$sec,rawdata$sec),signal=rep(c(1,-1),each=length(gamma1))) 

 colnames(mybdata)<-c('y','gamma1','gamma2','sec','side')
 mybdata$side<-as.factor(mybdata$side)
 levels(mybdata$side)<-c("Left","Right")
 
 #original gamma data (I added relativetime)
    
 mygdata<-data.frame(y=c(rawdata$heartbeatcorrected_L,rawdata$heartbeatcorrected_R),stim1=c(gamma1,gamma1),stim2=c(gamma2,gamma2),t=c(rawdata$sec,rawdata$sec),reltime<-c(rawdata$relativetime,rawdata$relativetime),signal=rep(c(1,-1),each=length(gamma1)))
 
colnames(mygdata)<-c('y','gamma1','gamma2','sec','relativetime','side')
mygdata$sidexgamma1<-mygdata$side*mygdata$gamma1
mygdata$side<-as.factor(mygdata$side)
levels(mygdata$side)<-c("Left","Right")
    #-----------------------------------------------------------------------------------------------#
    
    # filter out replicates in the dependent variable relating to the heartbeat correction (artificially induces autocorrelation if left in). The original pattern is sawtooth waveform after preprocessing, so sampling a single observation from the replicated observations reduced the computational load to estimate the model without affecting the fit as the autocorrelation is removed.
    #print(dim(mydata)[1]/2+1)
    #print(max(peaklist))
    
    #mydata_test<-mydata %>% group_by(y) %>% filter(t==min(t))
    mygdatax<-mygdata[c(peaklist,peaklist+(dim(mygdata)[1]/2+1)),] #db renamed to mydatax to preserve original mydata
    
    mybdatax<-mybdata[c(peaklist,peaklist+(dim(mybdata)[1]/2+1)),] #db renamed to mydatax to preserve original mydata
     w<-which(is.na(mybdatax$y))
    mybdatax<-mybdatax[-w,]
    
plot(mybdatax$sec[mybdatax$side=='Left'],mybdatax$y[mybdatax$side=='Left'],type='l',col='blue')
lines(mybdatax$sec[mybdatax$side=='Right'],mybdatax$y[mybdatax$side=='Right'],type='l',col='red')

    
    #print(dim(mydata_test))
    #print(dim(mydata_test2))
    #print(length(unique(mydata$y)))
    #print(ts.plot(mydata$y))#;abline(v=mydata$y[peaklist]))
    #new1<-ggplot(mydata,aes(y=y,x=t))+geom_line()+geom_vline(xintercept=mydata$t[c(peaklist,peaklist+(dim(mydata)[1]+1))],colour="red")
    #new2<-ggplot(mydata,aes(y=y,x=t))+geom_line()+geom_vline(xintercept=mydata$t[c(peaklist)],colour="green")
    #print(new1)
    #print(new2)
    #print("1")
    # set optimisation parameters 
    glsControl(optimMethod = "L-BFGS-B",maxIter = 100)
    
    #For now just a couple of flags to make it easier to switch between baselined and not
    usegdata=0
    thisdata<-mybdatax #DB added to give flexibility when comparing datasets
   
    
    # fit gam model 
    myfit <- gam(y~s(sec)+s(sec,by=side)+gamma1+gamma2+side+gamma1*side,data=thisdata)
    #print("2")
    myfit2 <- glm(y~gamma1+gamma2+sec+I(sec^2)+I(sec^3)+side+gamma1*side,data=thisdata)
    #print("3")
    #check fit of the model
    #print(appraise(myfit))
    
    #Try without gamma2
    myfit1a <- gam(y~s(sec)+s(sec,by=side)+gamma1+side+gamma1*side,data=thisdata)
    #print("2")
    myfit2a <- glm(y~gamma1+sec+I(sec^2)+I(sec^3)+side+gamma1*side,data=thisdata)
    
    #Try without interaction with side
      myfit2b <- glm(y~gamma1+gamma2+sec+I(sec^2)+I(sec^3)+side,data=thisdata)
      
      anova(myfit2b,myfit2,test="Chisq") #confirms sig interaction
    
    #DB - try just using relative time - this is hopeless!
    w<-which(is.na(mygdatax$relativetime))
    mygdatar <- mygdatax[-w,]
    myfit3<-glm(y~relativetime+I(relativetime^2)+I(relativetime^3)+side+relativetime*side,data=mygdatar)
    
    print(paste0("AIC_gam=",AIC(myfit)))
    print(paste0("AIC_glm=",AIC(myfit2)))
    print(paste0("BIC_gam=",BIC(myfit)))
    print(paste0("BIC_glm=",BIC(myfit2)))
    
    #print("4")
    #print(summary(myfit))
    #-----------------------------------------------------------------------------------------------#
    
    # Extract the parameter estimates and record them for later use. Data stored in data.frame called 'glm.data'.
 
    
    glm.data[j,7] <- "gamma"
    
    glm.data[j,2:6] <- anova(myfit)$'p.coeff'#myfit$lme$coefficients$fixed[1:6]
    
    glm.data[j,8] <- AIC(myfit2) #print(paste0("AIC_gam=",AIC(myfit)))
    glm.data[j,9] <- AIC(myfit) #print(paste0("AIC_glm=",AIC(myfit2)))
    glm.data[j,10] <- BIC(myfit2)#print(paste0("BIC_gam=",BIC(myfit)))
    glm.data[j,11] <- BIC(myfit)#print(paste0("BIC_glm=",BIC(myfit2)))
    
    #-----------------------------------------------------------------------------------------------#
    #setup plot data (wrangling data to work with plot)
  
    
    myplotdat<-data.frame(y=thisdata$y,x=thisdata$sec,fitted=predict(myfit),Side=thisdata$side)#$gam, type = "response"
    
    #plot the time series for each individual per side.
    g3<-ggplot(myplotdat,aes(y=y,x=x,colour=Side))+geom_point(aes(colour=Side),cex=.5,alpha=0.2)+geom_line(aes(y=fitted))+theme_bw()+theme(text=element_text(size=14))+ ggtitle(paste0(origWG$Filename[j],':_',origWG$lat[j]))+
    ylab('Normalised CBFV') + xlab('time(s)')
    
    # as we are fitting in a loop and printing to file, we need to use 'print' function with ggplot.
    print(g3)
    myfilepath<-here('GAM_figs_baselined')
    if(usegdata==1){
       myfilepath<-here('GAM_figs')
    }
    myfilename<-paste0(myfilepath,'/',origWG$Filename[j],'_GAM.jpg')
    ggsave(myfilename,g3)
    
    #================================================================================================#
  n2<-nrow(myplotdat)/2
  nforplot<-80
  range1<-1:nforplot
  range2<-range1+n2
    
    g4_epoch<-ggplot(myplotdat[c(range1,range2),],aes(y=y,x=x,colour=Side))+geom_point(aes(colour=Side),alpha=0.4)+geom_line(aes(y=fitted))+theme_bw()+theme(text=element_text(size=14))+ ylab('Normalised CBFV (cm/s)_epoch') + xlab('time(s)')
    
    print(g4_epoch)
    
    #output data
    glm_data<-glm.data
    
    
 myplotdatDB<-data.frame(y=mygdatar$y,x=mygdatar$relativetime,fitted=predict(myfit3),Side=mygdatar$side)#$gam, type = "response"
    
    #plot the time series for each individual per side.
    g5<-ggplot(myplotdatDB,aes(y=y,x=x,colour=Side))+geom_point(aes(colour=Side),cex=.5,alpha=0.2)+geom_line(aes(y=fitted))+theme_bw()+theme(text=element_text(size=14))+ ggtitle(paste0(origWG$Filename[j],':_',origWG$lat[j]))+
    ylab('Normalised CBFV') + xlab('time(s)')
  
 
#################################  ###################################################

```
#---------------------------------------------------------------------------------------------------#
#write.csv(my_results_LISA_WG_GAM_gamma,'/Users/paulthompson/Documents/fTCD_glm_results/Lisa_data/Fixed_HRF/gamma/results_LISA_WG_GAM_gamma.csv',row.names = FALSE)

my_results_LISA_WG_GAM_gamma_Jan2022<-my_results_LISA_WG_GAM_gamma_Jan2022[complete.cases(my_results_LISA_WG_GAM_gamma_Jan2022), ]
#---------------------------------------------------------------------------------------------------#


my_results_LISA_WG_GAM_gamma_ex_Jan2022 <- my_results_LISA_WG_GAM_gamma_Jan2022

#---------------------------------------------------------------------------------------------------#
# --------------------------------------------------------------------------------------------------#

#load LI based on old Doppler analysis method

old_res<-read.csv("/Users/paulthompson/Documents/fTCD_glm_results/Lisa_data/WordGen_results.csv")

old_res<-old_res %>% rename(ID=Filename)

compare_results_Jan2022<-merge(my_results_LISA_WG_GAM_gamma_ex_Jan2022,old_res,by='ID',all.x = T)

fmri_data <- read.csv('/Users/paulthompson/Documents/fTCD_glm_results/Lisa_data/Chapter5_fMRI_data.csv')

# Identify factors
factor_variables <- c('group_cat', 'group_lat', 'sex', 'hand_self_report', 'hand_QHP_cat', 'hand_EHI_cat', 'Old_fTCD_wg_cat', 'Old_fTCD_pptt_cat', 'fTCD_wg_cat', 'fTCD_pptt_cat')

for (i in 1:length(factor_variables))
{factor_ind <- str_which(colnames(fmri_data), paste0('^',factor_variables[i]))
fmri_data[,factor_ind] <- as.factor(fmri_data[,factor_ind])}

# Relabel group_cat and sex factors for clarity
# NB: group_cat 0=typical; 1=atypical
# sex 0=male; 1=female
levels(fmri_data$group_cat) <- c('T', 'A')
levels(fmri_data$sex) <- c('M', 'F')


fmri_data<-fmri_data[,c('ID','fMRI_diff_wg_frontal','fMRI_diff_wg_temporal','fMRI_diff_wg_MCA')]

compare_results2_Jan2022<-merge(compare_results_Jan2022,fmri_data,by='ID')

names(compare_results2_Jan2022)[c(13,6,21:23)] <- c('fTCD, existing method','fTCD, GAM method',"fMRI, frontal ROI","fMRI, temporal ROI","fMRI, MCA ROA")


#output plots (correlagram and Bland Altman.)

#jpeg(file = '/Users/paulthompson/Documents/fTCD_glm_results/Lisa_data/Fixed_HRF/gamma/HRF_signals_plots_LISA_WG_GAM_gamma_correlations.jpg')
psych::pairs.panels(compare_results2_Jan2022[,c('fTCD, existing method','fTCD, GAM method',"fMRI, frontal ROI","fMRI, temporal ROI","fMRI, MCA ROA")])
#GGally::ggpairs(compare_results2[,c('LI (mean diff)','LI (GAM model-based)',"fMRI LI (Frontal)","fMRI LI (temporal)","fMRI LI (MCA)")])+theme_bw()+theme(axis.text.x = element_text(angle = 45, hjust=1))
#dev.off()


#==================================================================#
ggally_cor_New<-
  function (data, mapping, ..., stars = TRUE, method = "pearson", 
            use = "complete.obs", display_grid = FALSE, digits = 3, title_args = list(...), 
            group_args = list(...), justify_labels = "right", align_percent = 0.5, 
            title = "Corr", alignPercent = warning("deprecated. Use `align_percent`"), 
            displayGrid = warning("deprecated. Use `display_grid`")) 
  {
    if (!missing(alignPercent)) {
      warning("`alignPercent` is deprecated. Please use `align_percent` if alignment still needs to be adjusted")
      align_percent <- alignPercent
    }
    if (!missing(displayGrid)) {
      warning("`displayGrid` is deprecated. Please use `display_grid`")
      display_grid <- displayGrid
    }
    na.rm <- if (missing(use)) {
      NA
    }
    else {
      (use %in% c("complete.obs", "pairwise.complete.obs", 
                  "na.or.complete"))
    }
    GGally::ggally_statistic(data = data, mapping = mapping, na.rm = na.rm, 
                             align_percent = align_percent, display_grid = display_grid, 
                             title_args = title_args, group_args = group_args, justify_labels = justify_labels, 
                             justify_text = "left", sep = if ("colour" %in% names(mapping)) 
                               ": "
                             else ":\n", title = title, text_fn = function(x, y) {
                               if (GGally:::is_date(x)) {
                                 x <- as.numeric(x)
                               }
                               if (GGally:::is_date(y)) {
                                 y <- as.numeric(y)
                               }
                               corObj <- stats::cor.test(x, y, method = method, 
                                                         use = use)
                               cor_est <- as.numeric(corObj$estimate)
                               cor_txt <- formatC(cor_est, digits = digits, format = "f")
                               if (isTRUE(stars)) {
                                 cor_txt <- str_c(cor_txt, GGally::signif_stars(corObj$p.value))
                                 cor_CI <- as.numeric(corObj$conf.int)
                                 cor_txt2 <- formatC(cor_CI, digits = digits, format = "f")
                                 cor_txt <- str_c(cor_txt, paste0("[",cor_txt2[1],',',cor_txt2[2],"]"),sep="\n")
                               }
                               cor_txt
                             })
  }

#==================================================================#
