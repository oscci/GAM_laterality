---
title: "R Notebook for GAM"
output: html_notebook
---

This is a notebook version based on PT's original epoched plot.R  

GAM model (without contrasts) for LISA data (Word Generation) - simple stimulus (stim1 and stim2) - both runs

For details of the general approach see 
Pedersen, E. J., Miller, D. L., Simpson, G. L., & Ross, N. (2019). Hierarchical generalized additive models in ecology: An introduction with mgcv. PeerJ, 7, e6876. https://doi.org/10.7717/peerj.6876


!!!!!!!!!!!! DB comment:
Original script says not downsampled, but this IS downsampled early on by taking every 4th point:  at this line: rawdata = filter(shortdat, row_number() %% 4 == 0)

```{r loadpackages}
library(osfr)
library(utils)
require(dplyr)
require(tidyverse)
require(boot)
require(fmri)
require(ggpubr)
library(psych)
#library(nlme)
library(plm)
require(mgcv)
library(blandr)
library(gratia) #tools to extend plotting and analysis of mgcv models by Pederson et al
library(performance)
library(GGally)
library(here)
library(magick) #for posthoc arranging created jpgs (better to do this as created)
```

The following is the main function to run the analysis. The function does the following in order:

PART 1:  

Script takes a raw .exp datafile and preprocesses it ready for GAM analysis:  
- It downsamples from 100 Hz to 25 Hz
- It identifies markers in the marker channel - these define epoch timings
- It creates a box car function showing when the task was ON or OFF - this is done separately for the period during word generation and word report. 
- It normalises the L and R fTCD signals to a mean of 100 by dividing by respective channel mean. This adjusts for any constant differences between L and R that may relate to angle of insonation.
- It performs heart beat integration (identified regular peaks in waveform and averages over the peak-to-peak interval). This removes a major, systematic source of variability that is of no interest.
- It creates a channel corresponding to the epoch number
- It performs baseline correction for each epoch separately for L and R by subtracting the mean value during the baseline period from the signal across the whole epoch. This ensures L and R are equated at the start of the epoch.
- It saves the processed data into a .csv file  
- The mean L and R plots after baseline correction are saved in GAM_figs_baselined (you need to create this as a subfolder if it does not already exist)

PART 2:  

- runs the gam  
- saves the parameter estimates to data.frame.  

PART 3:  

- plot the correlogram, Bland Altman plots, time series plots.  

```{r initialise}
#Here we read in background information about participants and set general task parameters

origWG <- read.csv(here('Bruckert_2016_data/WordGen_results.csv')) #this has laterality classification from original doppler  

## Set parameters and make file to hold results
samplingrate <- 25 # Sampling rate after downsampling. Raw data is 100Hz, we take 1 in every 4 samples
heartratemax <- 125 # Used to ensure that correspondence between peaks/heartbeats is in realistic range

# set up data.frame to hold the outputted parameter estimates from the GLMs.
order=3 #used later for the polynomial order

# Stimulus timings: Word Gen starts 5 seconds after marker and continues for 20 seconds (including REPORT phase)
# Edit: stim1 models covert word generation, which starts 5 seconds after marker and continues for 15 seconds
# stim2 models overt word reporting, which starts 20 seconds after marker and continues for 5 seconds
stim1_delay_sec <- 5
stim1_delay_samples <- stim1_delay_sec * samplingrate
stim1_length_sec <- 15
stim1_length_samples <- stim1_length_sec * samplingrate

stim2_delay_sec <- 20
stim2_delay_samples <- stim2_delay_sec * samplingrate
stim2_length_sec <- 5
stim2_length_samples <- stim2_length_sec * samplingrate

rest_length_sec <- 30
rest_length_samples <- rest_length_sec * samplingrate

delaytime_sec <- 0 #time after marker before start of response (default to zero)
delaysamples<- delaytime_sec*samplingrate

#Prepare a data frame to hold results if it does not already exist
thisname<-here('summary.csv')
if(!file.exists(thisname)){ #make summary file if it does not exist
  summary.data<-data.frame(matrix(NA,nrow=nrow(origWG),ncol=13))
  names(summary.data)<-c('ID',paste0('param',1:5),'method','AIC_glm','AIC_gam','BIC_glm','BIC_gam','p_interaction','R2')
  
  summary.data<-cbind(origWG,summary.data) #we'll include the results from original Lisa analysis for comparison
  write.csv(summary.data,here("summary.csv"),row.names=F)
}
summary.data<-read.csv(here("summary.csv"))

#NB for Word Generation task POI was 8 to 20 seconds



```
#For diagnosing issues with the script, just analyse 1 file at a time- can pick according to laterality


# w<-which(origWG$lat=='L') #can change to R or bilat, but for now just focus on L-lateralisd
# thisfile <- 2 #after grouping by lat, this is the nth file
# j <- w[thisfile] #number of file to be analysed specified here

#OR (defaults to this unless this is commented out)
#to run through all subjects





```{r preprocessing}  
ftcd_preprocess<-function(path,j) #DB added option j so this just runs one person at a time so I can understand it better!  
  
  #This does the steps listed above as part 1, and also saves a plot of the L and R channel means after baseline correction in GAM_figs_baselined
{
  # get all files names to be loaded in and preprocessed
  filename1<-list.files(path,pattern = '.exp')[j]
  
  #------------------------------------------------------------------------------------------------#
  ###########################################
  # PART 1: based on original fTCD analysis #
  #                                         #
  # Created by z.woodhead 30th July 2019    #
  # Edited  by z. woodhead 3rd Oct 2019  
  # Edited by DVMB June 2022                #
  ###########################################
  #------------------------------------------------------------------------------------------------#
  print(filename1)
  
  ## Read in raw data
  
  mydata<-read.table(paste0(path,"/",filename1), skip = 6,  header =FALSE, sep ='\t')
  
  wantcols = c(2,3,4,7) #sec, L, R,marker #select columns of interest to put in shortdat
  #NB markers correspond to values > 100 - should be around 24 short blocks of these- can see these with plot(shortdat$V7) for sanity check here
  shortdat = data.frame(mydata[,wantcols])
  rawdata = filter(shortdat, row_number() %% 4 == 0) # downsample from 100  Hz to 25 Hz by taking every 4th point (nb we still see markers, as duration of marker signal is much longer than 4 timepoints)
  allpts = nrow(rawdata) # total N points in long file
  rawdata[,1] = (seq(from=1,to=allpts*4,by=4)-1)/100 #create 1st column which is time in seconds from start
  colnames(rawdata) = c("sec","L","R","marker")
  
  
  #----------------------------------------------------------
  ## Find markers; place where 'marker' column goes from low to high value
  # Marker channel shows some fluctuation but massive increase when marker is on so easy to detect
  
  mylen = nrow(rawdata); # Number of timepoints in filtered data (rawdata)
  markerplus = c(rawdata$marker[1] ,rawdata$marker); # create vectors with offset of one
  markerchan = c(rawdata$marker,0); 
  markersub = markerchan - markerplus; # start of marker indicated by large difference between consecutive data points
  meanmarker <- mean(rawdata$marker) # We will identify big changes in marker value that are > 5 sds
  markersize <- meanmarker+4*sd(rawdata$marker)
  origmarkerlist = which(markersub>markersize)
  norigmarkers = length(origmarkerlist) #This should match the N markers on origWG
  
  #boxcar function for generation and reporting periods
  rawdata$stim1_on <- 0 #for generation period - default to zero; 1 when on
  rawdata$stim2_on <- 0 #for report period- default to zero; 1 when on
  for (m in 1:norigmarkers){
    rawdata$stim1_on[(origmarkerlist[m]+stim1_delay_samples):(origmarkerlist[m]+stim1_delay_samples+stim1_length_samples)] <- 1
    rawdata$stim2_on[(origmarkerlist[m]+stim2_delay_samples):(origmarkerlist[m]+stim2_delay_samples+stim2_length_samples)] <- 1
  }
  
  #if first marker is less than 300, pad the initial part of file by repeating initial values
  #These do not affect computations for standard method, but prevent crashes later on.
  
  firstm <-origmarkerlist[1]
  if (firstm<300){
    rawdata<-rbind(rawdata,rawdata[1:(301-firstm),])
    origmarkerlist = origmarkerlist+(301-firstm)
  }
  
  
  
  
  #---------------------------------------------------------- (ZW NEW)
  # Identify raw datapoints below .0001 quartile (dropout_points) and above .9999 quartile (spike_points)
  # (In our analysis we'd usually check these visually, as this criterion can miss them, but this allows us to take out extreme artefacts - usually v rare by definition)
  
  dropout_points <- c(which(rawdata$L < quantile(rawdata$L, .0001)), 
                      which(rawdata$R < quantile(rawdata$R, .0001)))
  
  spike_points <- c(which(rawdata$L > quantile(rawdata$L, .9999)),
                    which(rawdata$R > quantile(rawdata$R, .9999)))
  
  #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
  #DB_June : in original script these points were identified but not smoothed/deleted prior to normalisation.
  #I have modified to omit them from computation of mean (though it doesn't make much difference as they are so rare)
  
  
  #----------------------------------------------------------
  # Data normalisation: ensures L and R means are the same overall. NB does NOT use variance in this computation
  
  meanL=mean(rawdata$L[-c(dropout_points,spike_points)])
  meanR=mean(rawdata$R[-c(dropout_points,spike_points)])
  rawdata$normal_L=rawdata$L/meanL * 100 
  rawdata$normal_R=rawdata$R/meanR * 100
  #For the dropout and spiking timepoints, substitute the mean (added by DB)
  rawdata$normal_L[c(dropout_points,spike_points)]<-meanL
  rawdata$normal_R[c(dropout_points,spike_points)]<-meanR
  #----------------------------------------------------------
  # Heartbeat integration: we look for peaks in the signal that correspond to heart beat
  peaklist=numeric(0)
  pdiff=numeric(0)
  badp=numeric(0)
  
  # Look through every sample from 6, to number of samples minus 6
  for(i in seq(6,mylen-6))
  {if(
    (rawdata$L[i] > rawdata$L[i-5])
    & (rawdata$L[i] > rawdata$L[i-4])
    & (rawdata$L[i] > rawdata$L[i-3])
    & (rawdata$L[i] > rawdata$L[i-2])
    & (rawdata$L[i] > rawdata$L[i-1])
    & (rawdata$L[i] > rawdata$L[i+1])
    & (rawdata$L[i] > rawdata$L[i+2])
    & (rawdata$L[i] > rawdata$L[i+3])
    & (rawdata$L[i]> rawdata$L[i+4])
    & (rawdata$L[i]> rawdata$L[i+5]))
  {peaklist=c(peaklist,i)
  }
  }
  
  # Check that the heartbeats are spaced by far enough!
  peakdiffmin = 60/heartratemax * samplingrate
  pdiff <- peaklist[2:length(peaklist)]-peaklist[1:(length(peaklist)-1)] # pdiff is a list of the number of samples between peaks
  badp<-which(pdiff<peakdiffmin) # badp is a list of the pdiff values that are less than peakdiffmin
  if (length(badp) != 0)
  {peaklist<-peaklist[-(badp+1)] # update peaklist, removing peaks identified by badp
  }
  #print(dim(rawdata))
  #print(peaklist)
  # Do heart beat integration
  peakn=length(peaklist)
  rawdata$heartbeatcorrected_L <- 0
  rawdata$heartbeatcorrected_R <- 0 
  for (p in 1:(peakn-1))
  {myrange=seq(peaklist[p],peaklist[p+1]) # the indices where the heartbeat will be replaced
  thisheart_L=mean(rawdata$normal_L[myrange]) # the new values that will be replaced
  thisheart_R=mean(rawdata$normal_R[myrange])
  rawdata$heartbeatcorrected_L[peaklist[p] : peaklist[p+1]]=thisheart_L
  rawdata$heartbeatcorrected_R[peaklist[p] : peaklist[p+1]]=thisheart_R
  if (p==1){
    rawdata$heartbeatcorrected_L[1:peaklist[p]] <- thisheart_L
    rawdata$heartbeatcorrected_R[1:peaklist[p]] <- thisheart_R
  }
  if (p==peakn-1){
    rawdata$heartbeatcorrected_L[peaklist[p] : mylen] <- thisheart_L
    rawdata$heartbeatcorrected_R[peaklist[p] : mylen] <- thisheart_R
  }
  }
  
  #To inspect a portion of the data can  set seeprocessed to 1 which will run this bit:
  seeprocessed<-0 #nb usually set seeprocessed to zero.
  if(seeprocessed==1){
    plot(rawdata$sec[1:5000],rawdata$heartbeatcorrected_L[1:5000],type='l',col='blue')
    lines(rawdata$sec[1:5000],rawdata$heartbeatcorrected_R[1:5000],type='l',col='red')
    lines(rawdata$sec[1:5000],120*rawdata$stim1_on[1:5000]) #marker superimposed as block
  }
  #--------------------------------------------------------------------------------------------
  # Identify extreme datapoints with values below 60 and above 140
  
  extreme_points <- c(which(rawdata$heartbeatcorrected_L < 60),
                      which(rawdata$heartbeatcorrected_L > 140),
                      which(rawdata$heartbeatcorrected_R < 60),
                      which(rawdata$heartbeatcorrected_R > 140))
  
  #DB new: create columns showing epoch and time relative to epoch start for each epoch (see below)
  rawdata$epoch<-NA
  rawdata$relativetime<-NA #initialise new column
  
  # Epoch timings
  epochstart_time   <- -12
  epochend_time     <- 40.52 #full epoch duration is 52.52 #updated by DB to include all of rest period
  epochstart_index  <- epochstart_time * samplingrate
  epochend_index    <- epochend_time * samplingrate
  basestart_time    <- -10 # baseline start
  baseend_time      <- 0 # baseline end
  basestart_index   <- basestart_time * samplingrate
  baseend_index    <- baseend_time * samplingrate
  
  # myepoched will be the full epoched trial
  myepoched <- array(0, dim=c(norigmarkers,epochend_index - epochstart_index + 1, 2)) # Set up an empty matrix
  
  for(mym in 1:norigmarkers) # for trials
  { 
    index1 = origmarkerlist[mym] + epochstart_index # index1 is index of the timepoint at the start of the epoch
    index2 = origmarkerlist[mym] + epochend_index # index2 is the index of the timepoint at the end of the epoch
    
    rawdata$relativetime[index1:index2]<-seq(from=epochstart_time, to=epochend_time, by=.04)
    
    
    # If recording started late, the start of the epoch for trial 1 will be beyond the recorded range. 
    # If this doesn't affect the baseline period (ie, results will be unaffected), then replace with mean
    
    if (index1 > 0){
      myepoched[mym,,1]=rawdata$heartbeatcorrected_L[index1:index2] #L side
      myepoched[mym,,2]=rawdata$heartbeatcorrected_R[index1:index2]
    }
  }
  
  # Baseline correction - (added to rawdata by DB)
  basepoints=(basestart_index-epochstart_index):(baseend_index-epochstart_index) #all baseline points within epoch
  
  rawdata$baselinedL<-NA
  rawdata$baselinedR<-NA
  for (mym in 1:norigmarkers)
  {
    
    basemeanL=mean(myepoched[mym,basepoints,1]) #last dim is 3, which is HB corrected
    basemeanR=mean(myepoched[mym,basepoints,2])
    
    myepoched[mym,,1]=100+myepoched[mym,,1]-basemeanL #last dim 4 is HB and baseline
    myepoched[mym,,2]=100+myepoched[mym,,2]-basemeanR
    index1 = origmarkerlist[mym] + epochstart_index # index1 is index of the timepoint at the start of the epoch
    index2 = origmarkerlist[mym] + epochend_index # index2 is the index of the timepoint at the end of the epoch
    rawdata$baselinedL[index1:index2]<-myepoched[mym,,1]
    rawdata$baselinedR[index1:index2]<-myepoched[mym,,2]
    rawdata$epoch[index1:index2]<-mym
  }
  
  
  # Average over trials
  ntime <- dim(myepoched)[2]
  myepoched_average <- data.frame(
    "Lmean" <- rep(1, ntime),
    "Rmean" <- rep(1, ntime),
    "LRdiff" <- rep(1, ntime))
  
  myepoched_average$Lmean <- apply(myepoched[ , , 1], c(2), mean)
  myepoched_average$Rmean <- apply(myepoched[ , , 2], c(2), mean)
  myepoched_average$LRdiff <- myepoched_average$Lmean - myepoched_average$Rmean
  
  # # Plot myepoched_average
  
  
  myepoched_average$time<-seq(from=epochstart_time, to=epochend_time, by=.04)
  filepath<-here('GAM_figs_baselined')
  filename<-paste0(filepath,"/",origWG$Filename[j],"_avg.jpg")
  
  longepoched<-rbind(myepoched_average[4:7],myepoched_average[4:7])
  myrange<-1:nrow(myepoched_average)
  
  longepoched$Rmean[myrange]<-longepoched$Lmean[myrange]
  longepoched$Lmean<-'Right'
  longepoched$Lmean[myrange]<-'Left'
  colnames(longepoched)<-c('Side','CBV','diff','time')
  longepoched$Side<-as.factor(longepoched$Side)
  
  
  
  g1<-ggplot(data=longepoched, aes(x=time, y=CBV, group=Side)) +
    geom_line(aes(color=Side))+
    ggtitle(paste0(origWG$Filename[j],':_',origWG$lat[j]))
  
  ggsave(filename,g1)
  
  
  #remove outlier cases
  rawdata$heartbeatcorrected_L[extreme_points]<-NA
  rawdata$heartbeatcorrected_R[extreme_points]<-NA
  rawdata$baselinedL[extreme_points]<-NA
  rawdata$baselinedR[extreme_points]<-NA
  
  #add specification of original POI, 8 to 20 s
  rawdata$POI<-0
  w<-intersect(which(rawdata$relativetime>7.99),which(rawdata$relativetime<20.01))
  rawdata$POI[w]<-1
  
  return(list(rawdata,peaklist))
}
```


#########################################
# PART 2                                #
#                                       #
# Created by P.Thompson 17th Oct 2019   #
# Edited by P.Thompson 18th Oct 2019    #
# Edited by P.Thompson 30th June 2020 
# Edited by D.Bishop June 2022          #
#########################################


```{r makelongdata}
#This function was devised when testing basic gamma from canonical HRF.
#It is not used in final mgcv

makelong<-function(rawdata){
  
  
  # ggplot(data=rawdata[1:1000,], aes(x=sec, y=hrf)) +
  #   geom_line()
  # ggsave('hrf.jpg') #same for all participants!
  
  longdata<-rbind(rawdata,rawdata) #stack 2 versions on top of each other, one for L and one for R
  range1<-1:nrow(rawdata)
  longdata$R[range1]<-longdata$L[range1]
  longdata$normal_R[range1]<-longdata$normal_L[range1]
  longdata$heartbeatcorrected_R[range1]<-longdata$heartbeatcorrected_L[range1]
  longdata$baselinedR[range1]<-longdata$baselinedL[range1]
  longdata$L<-1
  longdata$L[range1]<-(-1)
  colnames(longdata)<-c('sec','side','rawdata','marker','stim1_on','stim2_on','x','normalised','xx','hbcorrected','epoch','relativetime','xxx','baselined','POI','hrf')
  longdata<-longdata[,-c(7,9,13)]
  longdata$side<-as.factor(longdata$side)
  levels(longdata$side)<-c('left','right')
  return(longdata)
}
```

```{r doGAM}
#Again, this is not used in final GAM, but was used for testing simpler models
# set optimisation parameters 
doGAM <-function(longdata,hrf,summary.data,usebdata){
  
  
  glsControl(optimMethod = "L-BFGS-B",maxIter = 100)
  
  #For now just a couple of flags to make it easier to switch between baselined and not
  longdata$y <- longdata$hbcorrected
  
  
  if (usebdata==1){
    longdata$y<-longdata$baselined #DB added to give flexibility when comparing datasets - some null values removed first
  }
  longdata<-longdata[!is.na(longdata$y),] #remove any with missing values
  # fit gam model 
  myfit <- gam(y~s(sec)+s(sec,by=side)+hrf+hrf*side,data=longdata)
  #Try without interaction with side
  myfit1b <- gam(y~s(sec)+s(sec,by=side)+hrf,data=longdata)
  pinteract<-anova(myfit,myfit1b,test="Chisq") #confirms sig interaction
  
  
  #print("2")
  myfit2 <- glm(y~hrf+sec+I(sec^2)+I(sec^3)+side+hrf*side,data=longdata)
  #print("3")
  #check fit of the model
  #print(appraise(myfit))
  
  
  
  
  
  # print(paste0("AIC_gam=",AIC(myfit)))
  # print(paste0("AIC_glm=",AIC(myfit2)))
  # print(paste0("BIC_gam=",BIC(myfit)))
  # print(paste0("BIC_glm=",BIC(myfit2)))
  
  #print("4")
  #print(summary(myfit))
  #-----------------------------------------------------------------------------------------------#
  
  # Extract the parameter estimates and record them for later use. Data stored in data.frame called 'summary.data'.
  
  
  summary.data$method[j] <- gam.method
  w<-which(colnames(summary.data)=='param1')
  
  summary.data[j,w:(w+3)] <- anova(myfit)$'p.coeff'  #myfit$lme$coefficients$fixed[1:6]
  #for model with just one bold term, these correspond to intercept, hrf,side, hrf*side and 5th is blank
  
  summary.data$AIC_glm[j] <- round(AIC(myfit2),1) #print(paste0("AIC_gam=",AIC(myfit)))
  summary.data$AIC_gam[j] <- round(AIC(myfit),1) #print(paste0("AIC_glm=",AIC(myfit2)))
  summary.data$BIC_glm[j] <- round(BIC(myfit2),1)#print(paste0("BIC_gam=",BIC(myfit)))
  summary.data$BIC_gam[j] <- round(BIC(myfit),1)#print(paste0("BIC_glm=",BIC(myfit2)))
  summary.data$p_interaction[j] <- pinteract$`Pr(>Chi)`[2]
  summary.data$R2[j]<-summary(myfit)$r.sq #proportion of variance explained; 
  #see https://www.rdocumentation.org/packages/mgcv/versions/1.8-40/topics/summary.gam for explanation of terms
  return(list(summary.data,myfit,myfit2,longdata))
}
```

```{r paul-original-gamma}
fmri.stimulus.PT2<- function(scans,stim, onsets, durations, TR,scale)
{
  onsets <- onsets * TR
  durations <- durations * TR
  onsets <- onsets * scale
  durations <- durations * scale
  scans <- scans * TR * scale
  TR <- TR/scale
  no <- length(onsets)
  durations <- rep(durations, no)
  stimulus<-stim
  
  .gammaHRF <- function(t, par = NULL) {
    th <- 0.242 * par[1]
    1/(th * factorial(3)) * (t/th)^3 * exp(-t/th)
  }
  par <- floor((durations[1]/28)*4)
  
  y <- .gammaHRF(0:(durations[1] * scale)/scale, par) 
  
  stimulus <-  convolve(stimulus, rev(y), type = "open")
  stimulus <- stimulus[unique((scale:scans)%/%(scale^2 * TR)) * scale^2 * TR]/(scale^2 * TR)
  stimulus <- stimulus - mean(stimulus)
  return(stimulus)
}  
```


```{r paul-do-gam}
# Create convolved stimulus function with HRF (applying the new fmri.stimulus.PT2 function above)

paul_gam<-function(rawdata,stim1_length_samples,stim2_length_samples,peaklist,summary.data,usebdata,order,gam.method){
  
  scans = nrow(rawdata)
  stim=rawdata$stim1_on
  onsets = which(diff(rawdata$stim1_on)==1) #point at which stim1_on series starts - NB did have onsets and offsets
  durations = stim1_length_samples
  TR = 1
  scale=1
  gamma1 = fmri.stimulus.PT2(scans,stim, onsets, durations, TR,scale)
  
  stim=rawdata$stim2_on
  stim2_length_samples
  gamma2 = fmri.stimulus.PT2(scans,stim, onsets, durations, TR,scale)
  #-----------------------------------------------------------------------------------------------# 
  # Binds all the stimuli into one matrix to be read into the fmri.design function. This converts the data into a design matrix and adds in the drift terms according to the order argument specified by the user.
  gamma = as.matrix(cbind(gamma1,gamma2))
  gamma = rbind(gamma,gamma)
  
  #-----------------------------------------------------------------------------------------------#
  
  # We create the design matrix and bind them together to give the same design matrix for each side (left and right), so that the main effect of side can be modelled appropriately.
  my_des<-fmri.design(gamma, order = order)
  
  # Add a dummy variable for side (signal). This is either 0 or 1 for left and right respectively.
  my_des<-cbind(my_des,rep(1:0,each=length(gamma1)))
  
  # Add a dummy variable for interaction
  my_des<-cbind(my_des,rep(1:0,each=length(gamma1))) #
  
  # Add interaction variable for side (side*stim1).
  my_des[,8]<-my_des[,8]*my_des[,1]
  
  # Use the design matrix to finish constructing the data for each GLM. 
  
  my_des[,7]<-dplyr::recode(my_des[,7], `0` = -1L, `1` = 1L)
  #-----------------------------------------------------------------------------------------------#
  
  #  mydata<-data.frame(y=c(rawdata$heartbeatcorrected_L,rawdata$heartbeatcorrected_R),stim1=my_des[,1],stim2=my_des[,2],t=my_des[,4],side=as.factor(my_des[,7]),stim1_side=my_des[,8])
  
  rawdata$gamma1<-gamma1
  rawdata$gamma2<-gamma2
  
  
  # filter out replicates in the dependent variable relating to the heartbeat correction (artificially induces autocorrelation if left in). The original pattern is sawtooth waveform after preprocessing, so sampling a single observation from the replicated observations reduced the computational load to estimate the model without affecting the fit as the autocorrelation is removed.
  
  
  shortdata<-rawdata[peaklist,] #data reduction
  
  
  w<-which(is.na(shortdata$epoch)) #remove rows with missing data
  shortdata<-shortdata[-w,]
  
  #create long form 
  longdata<-rbind(shortdata,shortdata)
  
  range1<-1:nrow(shortdata)
  longdata$heartbeatcorrected_R[range1]<-longdata$heartbeatcorrected_L[range1]
  longdata$baselinedR[range1]<-longdata$baselinedL[range1]
  longdata$L<-1
  longdata$L[range1]<-(-1)
  colnames(longdata)<-c('sec','side','rawdata','marker','stim1_on','stim2_on','x','normalised','xx','hbcorrected','epoch','relativetime','xxx','baselined','POI','gamma1','gamma2')
  longdata<-longdata[,-c(7,9,13)]
  longdata$y <- longdata$hbcorrected
  if(usebdata==1){
    longdata$y <- longdata$baselined
  }
  longdata$side<-as.factor(longdata$side)
  levels(longdata$side)<-c('left','right')
  
  #-----------------------------------------------------------------------------------------------#
  
  
  
  
  # set optimisation parameters 
  glsControl(optimMethod = "L-BFGS-B",maxIter = 100)
  
  # fit gam model 
  # Paul original model (here, model 3), with terms renamed to be easier to understand
  
  #DB comment: I am not sure whether we need the s(sec, by=side) term. My understanding from Pederson et al is that this gives different smoothers for L and R; 
  if(gam.method==3){
    myfit <- gam(y~s(sec)+s(sec,by=side)+gamma1+gamma2+side+gamma1*side,data=longdata)
  }
  
  if(gam.method==4){
    longdata$epoch<-as.factor(longdata$epoch) #instead of time, use relativetime and epoch (latter as factor).
    myfit <- gam(y~s(relativetime)+s(relativetime,by=epoch)+gamma1+gamma2+side+gamma1*side,data=longdata)
  }
  
  if(gam.method==5){
    #model type 5 - just relative time and POI
    myfit <- gam(y~s(relativetime)+POI+side+POI*side,data=longdata)
  }
  
  if(gam.method==6){
    #model type 6
    myfit <- gam(y~s(sec)+s(relativetime)+POI+side+POI*side,data=longdata)
  }
  
    if(gam.method==7){
    #model type 7
    myfit <- gam(y~s(sec)+s(relativetime)+gamma1+gamma2+side+gamma1*side,data=longdata)
    }
  
      if(gam.method==8){
    #model type 7
    longdata$epoch<-as.factor(longdata$epoch) #instead of time, use relativetime and epoch (latter as factor).
    myfit <- gam(y~s(relativetime)+s(relativetime,by=epoch)+POI+side+POI*side,data=longdata)
    }
  
  
  #GLM with quadratic and cubic terms as comparison - this uses gamma1 interaction and is comparable to method 3. Have not yet modified for other methods, but could do so
  myfit2 <- glm(y~gamma1+gamma2+sec+I(sec^2)+I(sec^3)+side+gamma1*side,data=longdata)
  
  #check fit of the model
  #print(appraise(myfit))
  
  s<-summary(myfit)
  sp<-s$p.pv #pvalues of coefficients
  
  pinteract<-round(sp[length(sp)],2)
  
  summary.data$method[j] <- gam.method
  w<-which(colnames(summary.data)=='param1')
  ncoeffs<-length(sp)
  summary.data[j,w:(w+ncoeffs-1)] <- anova(myfit)$'p.coeff' 
  colnames(summary.data)[(w+ncoeffs-1)]<-'side.interact'
  #myfit$lme$coefficients$fixed[1:6]
  #for model with just one bold term, these correspond to intercept, hrf,side, hrf*side and 5th is blank
  
  summary.data$AIC_glm[j] <- round(AIC(myfit2),1) #print(paste0("AIC_gam=",AIC(myfit)))
  summary.data$AIC_gam[j] <- round(AIC(myfit),1) #print(paste0("AIC_glm=",AIC(myfit2)))
  summary.data$BIC_glm[j] <- round(BIC(myfit2),1)#print(paste0("BIC_gam=",BIC(myfit)))
  summary.data$BIC_gam[j] <- round(BIC(myfit),1)#print(paste0("BIC_glm=",BIC(myfit2)))
  summary.data$p_interaction[j] <- pinteract
  summary.data$R2[j]<-summary(myfit)$r.sq #proportion of variance explained;
  allreturn <-list(summary.data,myfit,myfit2,longdata)
  return(allreturn)
}
```




MAIN ANALYSIS LOOP STARTS HERE

```{r run-analysis}
gamlist<-c('Canonical hrf 5s from marker1',
           'Boxcar POI',
           'PT original gamma',
           'PT modified gamma with relativetime x epoch',
           'with relative time and POI',
           'with sec,relative time and POI',
           'with sec,relative time and gammas',
            'with sec,relative timexepoch and POI')

gam.method <- 8 #method 1 uses canonical hrf for 5 s duration from marker onset
#method 2 is boxcar with POI
usebdata=0 #if zero, then use unbaselined heartbeatcorrected data, otherwise baselined by epoch
startj<-1
endj<-nrow(summary.data)
endj=10

for (j in startj:endj){
  #run ftcd_preprocess function before running this chunk, so functions are in memory
  #Need to have folder GAM_figs_baselined
  
  mypath<-here("Bruckert_2016_data/Chpt4_fTCD_WordGen_rawdata")
  myreturn<-ftcd_preprocess(path=mypath,j)
  rawdata<-myreturn[[1]]
  peaklist<-myreturn[[2]]
  
  for (gam.method in c(3,4,6,8)){
  if(gam.method!=3){ #used for testing program with simpler functions than final
    hrf<- fmri.stimulus(scans = nrow(rawdata),
                        onsets = which(diff(rawdata$stim1_on)==1), #point at which stim1_on series starts
                        durations = 175,  #altered from 375 to cover shorter period
                        TR = 1,
                        scale=1,
                        type='canonical')
    
    rawdata$hrf<-hrf
    
    #downsample to one heartbeat per datapoint using peaklist
    mydata<-rawdata[peaklist,]
    longdata<-makelong(mydata)
    
    if(gam.method==1){ #canonical hrf with short duration
      hrf<-hrf}
    if(gam.method==2){
      hrf<-longdata$POI} #boxcar with POI
    gamreturn<-doGAM(longdata,hrf,summary.data,usebdata)
  }
  
  
  if(gam.method>2){ #using the more complex GAM
    gamreturn<-paul_gam(rawdata,
                        stim1_length_samples,
                        stim2_length_samples,
                        peaklist,
                        summary.data,
                        usebdata,
                        order,
                        gam.method) #recorded on summary.data
    
  }
  
  summary.data<-gamreturn[[1]]
  myfit<-gamreturn[[2]]
  myfit2<-gamreturn[[3]]
  longdata<-gamreturn[[4]]
  w<-which(is.na(longdata$y)) #points with no data are those where insufficient series for HB detection - at start or end of block
  if(length(w)>0){
    longdata<-longdata[-w,]}
  
  
  #-----------------------------------------------------------------------------------------------#
  #setup plot data (wrangling data to work with plot)
  
  longdata$fitted<-fitted(myfit)
  longdata$y<-longdata$baselined
  if(usebdata==0){
    longdata$y<-longdata$hbcorrected
  }
  
  
  #plot the time series for each individual per side.
  g3<-ggplot(longdata,aes(y=y,x=sec,colour=side))+
    geom_line(aes(colour=side),alpha=0.4)+
    geom_line(aes(y=fitted))+
    theme_bw()+
    theme(text=element_text(size=14))+ 
    ggtitle(paste0(origWG$Filename[j],':_',origWG$lat[j]))+
    #add some data on this subject; NB x and y coords just set by trial and error here
    annotate(geom="text", x=280, y=112, label=paste0("R2=",round(summary.data$R2[j],3)))+
    annotate(geom="text", x=400, y=116, label=paste0("p.interaction=",round(summary.data$p_interaction[j],3)))+
    annotate(geom="text", x=550, y=120, label=paste0("Original LI=",summary.data$LI[j]," (",summary.data$lowCI[j],",",summary.data$hiCI[j],")"))+
    annotate(geom="text", x=550, y=85, label=paste0(gamlist[gam.method],": baselined=",usebdata))+
    ylab('Normalised CBFV') + 
    xlab('time(s)')
  
  # as we are fitting in a loop and printing to file, we need to use 'print' function with ggplot.
  print(g3)
  
  
  myfilepath<-here(paste0('method',gam.method,'_GAM_figs_baselined'))
  if(usebdata==0){
    myfilepath<-here(paste0('method',gam.method,'_GAM_figs'))
  }
  lapply(myfilepath[!myfilepath %in% here()], dir.create) #make directory if it does not exist
  
  myfilename<-paste0(myfilepath,'/',origWG$Filename[j],'_GAM.jpg')
  
  ggsave(myfilename,g3)
  
  #================================================================================================#
  #Just do one epoch
  thisepoch=10
  g4<-ggplot(longdata[longdata$epoch==thisepoch,],aes(y=y,x=sec,colour=side))+
    geom_line(aes(colour=side),alpha=0.4)+
    geom_line(aes(y=fitted))+
    theme_bw()+
    theme(text=element_text(size=14))+ 
    ggtitle(paste0(origWG$Filename[j],':_',origWG$lat[j]))+
    ylab('Normalised CBFV') + 
    xlab('time(s)')
  
  myfilename<-paste0(myfilepath,'/',origWG$Filename[j],'_GAM_epoch_',thisepoch,'.jpg')
  ggsave(myfilename,g4)
  

filename<-paste0('method',gam.method,'_summary.csv')
write.csv(summary.data,filename,row.names=F)

mycolor<-c('darkblue','green')

g5<-ggplot(data=longdata, aes(x=relativetime, y=y, colour=side,group=epoch)) +
  facet_wrap(~epoch) +
  geom_line(aes(colour=side),alpha=0.35)+
   geom_line(aes(y=fitted))+
    theme_bw()
  
myfilename<-paste0(myfilepath,'/',origWG$Filename[j],'_GAM_allepoch.jpg')
ggsave(myfilename,g5)
  }
 }         

#Some preliminary explorations
#Param 4 is parameter for interaction
myr<-round(cor(summary.data$LI,summary.data$side.interact),3)
plot(summary.data$LI,summary.data$param5,col=as.factor(summary.data$lat),main=myr)

#This is % var explained by model
myr<-round(cor(summary.data$LI,summary.data$R2),3)
plot(summary.data$LI,summary.data$R2,col=as.factor(summary.data$lat),main=myr)


plot(summary.data$side.interact,log(summary.data$p_interaction),col=as.factor(summary.data$lat))
r=cor.test(summary.data$LI,summary.data$side.interact)$estimate

plot(summary.data$LI,summary.data$side.interact,col=as.factor(summary.data$lat),main=r)

```

```{r assemblefigs}
#for now doing this with magick

for (i in 1:10){
  thisname<-summary.data$Filename[i]
#difficult to do in loop!
  m = 3
    thisfolder<-paste0('method',m,'_GAM_figs/')
    thisfile<-paste0(thisfolder,thisname,'_GAM.jpg')
    image1<-image_read(here(thisfile))
    thisfile<-paste0(thisfolder,thisname,'_GAM_epoch_10.jpg')
    image2<-image_read(here(thisfile))
     thisfile<-paste0(thisfolder,thisname,'_GAM_allepoch.jpg')
    image2a<-image_read(here(thisfile))
   m = 4
    thisfolder<-paste0('method',m,'_GAM_figs/')
    thisfile<-paste0(thisfolder,thisname,'_GAM.jpg')
    image3<-image_read(here(thisfile))
    thisfile<-paste0(thisfolder,thisname,'_GAM_epoch_10.jpg')
    image4<-image_read(here(thisfile))
      thisfile<-paste0(thisfolder,thisname,'_GAM_allepoch.jpg')
    image4a<-image_read(here(thisfile))
      m = 6
    thisfolder<-paste0('method',m,'_GAM_figs/')
    thisfile<-paste0(thisfolder,thisname,'_GAM.jpg')
    image5<-image_read(here(thisfile))
    thisfile<-paste0(thisfolder,thisname,'_GAM_epoch_10.jpg')
    image6<-image_read(here(thisfile))
     thisfile<-paste0(thisfolder,thisname,'_GAM_allepoch.jpg')
    image6a<-image_read(here(thisfile))
   m = 8
    thisfolder<-paste0('method',m,'_GAM_figs/')
    thisfile<-paste0(thisfolder,thisname,'_GAM.jpg')
    image7<-image_read(here(thisfile))
    thisfile<-paste0(thisfolder,thisname,'_GAM_epoch_10.jpg')
    image8<-image_read(here(thisfile))
     thisfile<-paste0(thisfolder,thisname,'_GAM_allepoch.jpg')
    image8a<-image_read(here(thisfile))
    


image12<-c(image1, image2)
image12<-image_append(image_scale(image12, "x200"),stack=F)
image12<-image_annotate(image12,' myfit <- gam(y~s(sec)+s(sec,by=side)+gamma1+gamma2+side+gamma1*side,data=longdata)',boxcolor="white",location="+50+160")
image34<-c(image3, image4)
image34<-image_append(image_scale(image34, "x200"),stack=F)
image34<-image_annotate(image34,' myfit <- gam(y~s(relativetime)+s(relativetime,by=epoch)+gamma1+gamma2+side+gamma1*side,data=longdata)',boxcolor="white",location="+50+160")
image56<-c(image5, image6)
image56<-image_append(image_scale(image56, "x200"),stack=F)
image56<-image_annotate(image56,' myfit <- gam(y~s(sec)+s(relativetime)+POI+side+POI*side,data=longdata)',boxcolor="white",location="+50+160")
image78<-c(image7, image8)
image78<-image_append(image_scale(image78, "x200"),stack=F)
image78<-image_annotate(image78,' myfit <- gam(y~s(relativetime)+s(relativetime,by=epoch)+POI+side+POI*side,data=longdata)',boxcolor="white",location="+50+160")

imageall<-c(image12,image56,image34,image78)
imageall<-image_append(image_scale(imageall, "x200"),stack=T)



writepath<-here("compositefigs")
writepath<-paste0(writepath,'/',thisname,'.png')
image_write(imageall,path=writepath,format='png')

imagealle1<-c(image2a,image6a)
imagealle1<-image_append(image_scale(imagealle1, "x200"),stack=T)
writepath<-here("compositefigs")
writepath<-paste0(writepath,'/',thisname,'_epochs_mods3_6.png')
image_write(imagealle1,path=writepath,format='png')

imagealle2<-c(image4a,image8a)
imagealle2<-image_append(image_scale(imagealle2, "x200"),stack=T)
writepath<-here("compositefigs")
writepath<-paste0(writepath,'/',thisname,'_epochs_mods4_8.png')
image_write(imagealle2,path=writepath,format='png')
}
```

